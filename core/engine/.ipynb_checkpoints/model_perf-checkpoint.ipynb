{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dd/66st0dhj4239w1xp36stpltm0000gn/T/ipykernel_61837/1079276200.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#Our text classifier, we focused on something simple and light for 3 reasons: easy conversion to JS, light storage and fast predictions\n",
    "\n",
    "#Importing libraries\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#Loading the dataset\n",
    "train_data = pd.read_csv('AI/train.csv')[:10000]\n",
    "\n",
    "#Extracting the labels\n",
    "classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train_data[classes].values\n",
    "\n",
    "#Lowercase\n",
    "train_sentences = train_data[\"comment_text\"].str.lower()\n",
    "\n",
    "max_features = 5000\n",
    "max_len = 150\n",
    "embed_size = 300\n",
    "\n",
    "#Tokenize (creates a word index, converting the most recurrent words into floats)\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "#Convert the sentences of the dataset into lists of floats using the tokenizer\n",
    "X_train = tokenizer.texts_to_sequences(train_sentences)\n",
    "\n",
    "#Pad the lists with zeroes so that every list has the same size to be fed to the neural network\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "\n",
    "#Simple neural network\n",
    "model1 = keras.models.Sequential()\n",
    "model1.add(keras.layers.Embedding(input_dim=vocab_size,output_dim=embed_size,input_length=max_len))\n",
    "model1.add(keras.layers.Flatten())\n",
    "model1.add(keras.layers.Dense(100,activation = 'relu'))\n",
    "model1.add(keras.layers.Dense(10,activation = 'relu'))\n",
    "model1.add(keras.layers.Dense(6,activation = 'sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "saved_model = \"newCp.ckpt\"\n",
    "cp_callback = ModelCheckpoint(saved_model, save_weights_only=True, verbose=1, save_best_only=True)\n",
    "\n",
    "#Training\n",
    "batch_sz = 32\n",
    "epoch = 2\n",
    "model1.fit(X_train, y, batch_size=batch_sz, epochs=epoch, validation_split=0.1, callbacks=[cp_callback])\n",
    "\n",
    "#Saving the model for conversion to JS\n",
    "keras.models.save_model(model1,\"newModel\")\n",
    "\n",
    "def detect(testList):\n",
    "    \"\"\"\n",
    "    Detects if a text contains insulting, toxic, obscene... content\n",
    "    :param testList: list of sentences to analyze\n",
    "    :type testList: List\n",
    "    :return: [toxic, severe_toxic, obscene, threat, insult, identity_hate] list of floats between 0 and 1, 1 meaning toxic or...\n",
    "    :rtype: List\n",
    "    \"\"\"\n",
    "    X_test = tokenizer.texts_to_sequences(testList)\n",
    "    print(X_test)\n",
    "    X_test = pad_sequences(X_test, padding='post', maxlen=max_len)\n",
    "    print(X_test)\n",
    "    return model1.predict(X_test)\n",
    "\n",
    "#Quick test (Disclaimer: offensive)\n",
    "print(detect([\"nigger\",\"You guys are really dumb\",\"Fuck you!\",\"Hello I am black\",\" you fucking niggers I hate you\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dd/66st0dhj4239w1xp36stpltm0000gn/T/ipykernel_61837/2262465292.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
